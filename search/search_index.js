var __index = {"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":"<p>Welcome to Orebit! Orebit is your personal assistant for navigating the world of MineCraft. He's here to do the tasks you don't want to do, freeing up your time to do what you'd rather do.</p> <p>Check out the side bar for a list of features, functions, and general info on how Orebit works. If you're looking for something in particular, check out the search bar in the top-right.</p>"},{"location":"index.html#installation","title":"Installation","text":"<p>Looking to install Orebit on your own server? Check out our Installation Guide.</p>"},{"location":"index.html#contributing","title":"Contributing","text":"<p>Want to contribute to the Orebit project? Thanks! I'll provide details here later on how you can help.</p>"},{"location":"index.html#why-orebit","title":"Why \"Orebit\"?","text":"<ul> <li>Ore = the stuff you mine for</li> <li>Bit = a computer</li> </ul> <p>Also, like a good little helper, he's always hanging out in your orbit.</p>"},{"location":"index.html#special-thanks-and-inspiration","title":"Special Thanks and Inspiration","text":"<p>Orebit was inspired by my wife, who I keep asking to play MineCraft with me but she always says she finds it so boring to gather resources and wishes she could just build and play without all of the grinding.</p> <p>While the task system and pathfinding were originally conceived without prior knowledge of existing mods or tools, shortly into the project I looked up what tools might already exist.</p> <p>While I take pride in stating plainly that I did not copy or steal ideas from these projects, I did look at their implementation after planning my own to see if others had the same ideas or if I was building something completely out of left field.</p>"},{"location":"index.html#baritone","title":"Baritone","text":"<p>Baritone is advertised as \"Google Maps for Block Game\". It primarily provides a pathfinding system allowing your character to automatically travel to any specified location or block type.</p> <p>I was pleased to see that Baritone also:</p> <ul> <li>Settled on a modified version of <code>A*</code> for pathfinding, building a graph of    valid moves rather than using simple unit steps on a grid</li> <li>Represented distant locations using a compact format and only focused on    local path correctness, lazily evaluating more distant parts of the path when    they became relevant</li> <li>Wrote replacements for block access utilities since the built-in ones are    terribly slow and inefficient</li> <li>Considered how placing or breaking blocks could mutate the grid during the    course of following a path, and factored this into path planning</li> </ul> <p>That said, there are a few key areas where I believe my implementation will outshine Baritone:</p> <ul> <li>Rather than simply attempting to speed up block data access, I bypass it    completely by generating an alternate representation of the world that's    optimized specifically for pathfinding</li> <li>Rather than the simple but hardly-useful 2 bits per chunk representation of    distant locations, I build a much larger (roughly 30kb) region tree for each    chunk, enabling hierarchical pathfinding and efficient block search</li> </ul> <p>The end result is faster and more accurate block search and pathfinding over significantly larger distances.</p>"},{"location":"index.html#alto-clef","title":"Alto Clef","text":"<p>Alto Clef is a mod built on top of Baritone that adds an extra layer of complexity: tasks. This way you can give your bot a complex string of commands such as:</p> <ul> <li>Navigate to a tree</li> <li>Break it</li> <li>Collect the wood</li> <li>Craft a crafting table</li> <li>Craft a wooden pick</li> <li>Navigate to stone</li> <li>Mine it</li> <li>Craft a furnace</li> </ul> <p>This bot was the first one to autonomously beat MineCraft without any human input.</p> <p>I was pleased to see that Alto Clef also:</p> <ul> <li>Uses a tree to represent the prerequisites for tasks</li> <li>Uses multiple state machines to interrupt behavior for higher priority tasks    like eating or self-defense</li> <li>Adds an Event Bus for updating bot state</li> </ul> <p>Truth be told, the implementation was almost exactly what I planned on building, with maybe minor variation in the representation of task sub-trees.</p>"},{"location":"pathfinding.html","title":"Pathfinding","text":"<p>TBD: Explanation for how it works</p>"},{"location":"pathfinding.html#region-level","title":"Region-level","text":"<p>Explanation</p>"},{"location":"pathfinding.html#block-level","title":"Block-level","text":"<p>Explanation</p>"},{"location":"pathfinding.html#movements","title":"Movements","text":"<p>Offsets below are listed as:</p> <pre><code>(direction of motion)\n(vertical axis)\n(orthogonal axis)\n</code></pre> <p>In other words, we assume the movement is being  taken in the X direction then record the X,Y,Z  offset.</p> <p>Offsets with a colon (<code>:</code>) indicate a range of possible values. For instance, <code>-1:2</code> implies values of -1, 0, 1, or 2 (inclusive).</p> Move Valid Directions Offset Walk 4 (N, E, S, W) 1, 0, 0 Diagonal 4 (NE, SE, NW, SW) 1, 0, 1 Ascend 4 (N, E, S, W) 1, 1, 0 Descend 4 (N, E, S, W) 1, -1, 0 Jump_1 12 (see image) 2, 0, -1:1 Jump_2 16 (see image) 3, 0, -1:1 Jump_3 24 (see image) 4, 0, -1:1 Climb 2 0, (-1 or 1), 0 Fall 1 0, -1, 0 Break 109* 0, 0, 0 Place 8 0, 0, 0 <p>Walk: As the name implies, this is an instruction to walk from one block to another. This is only possible if the blocks are at the same height and are adjacent to one another.</p> <p>Diagonal: As the name implies, this is an instruction to walk diagonally. This instruction requires that four blocks all share a height: the starting position, the destination position, and the two cardinal directions. For example, to move northeast there must be flat ground to the north and the east.</p> <p>Ascend: This refers to traveling up a 1-block stair step. This motion requires both a movement and a jump.</p> <p>Descend: This refers to traveling down a 1-block stair step. This motion only requires walking, as gravity will handle the change in height.</p> <p>Jump_X: This refers to jumping over a gap and landing on a block at the same height. As this movement travels more than a single block</p>"},{"location":"worldmodel.html","title":"World Model","text":""},{"location":"worldmodel.html#region-level","title":"Region-Level","text":""},{"location":"worldmodel.html#block-level","title":"Block-Level","text":"<p>In order to rapidly evaluate what movements are possible from a given block, we pre-compute data at every block which facilitates these computations.</p> <p>The data computed is listed below:</p> Datum Bit Length Meaning Stand Height 2 0 = intangible (e.g. air, flowers)1 = special (e.g. carpet)2 = half-block (e.g. slab)3 = full block (e.g. stone) Headroom 2 0, 1, 2, or \"3+\" blocks of air above this block Slow 1 Whether walking on this block will slow the player (e.g. block is soul sand, OR has cobweb on top of it) Hardness 3 Stores \\(floor(log_2(min(hardness, 31)*8))+1\\) for approximating break difficulty"},{"location":"Optimizations/index.html","title":"Index","text":"<p>A large amount of time, thought, and effort has gone into making Orebit as fast as possible at runtime with the smallest possible footprint in RAM. These pages document some of the design decisions and explain the algorithms, data structures, and techniques used to achieve these goals.</p>"},{"location":"Optimizations/block_reading.html","title":"Block reading","text":"<p>The standard way to read data about a block in MineCraft v1.21.4 Fabric is to use the following code:</p> <pre><code>World world; // The MineCraft world\nint x, y, z; // The block you're interested in\n\nBlockPos blockPos = new BlockPos(x, y, z);\nBlockState state = world.getBlockState(blockPos);\n\n// Is Solid:\nstate.isSolidBlock(world, blockPos);\n\n// Is Liquid:\n!state.getFluidState().isEmpty();\n\n// Is Climbable:\nstate.isIn(BlockTags.CLIMBABLE);\n\n// Redstone Power:\nworld.getReceivedStrongRedstonePower(blockPos);\n\n// Orientation:\nstate.get(Properties.FACING);\n\n// etc...\n</code></pre> <p>This works, the problem is that it's slow.</p> <p>To benchmark how slow, I ran a script that read 100 blocks randomly within a 5 chunk radius of the player and averaged the time to read. Running this on my M1 16-inch 2021 Macbook Pro, it takes around 3000000 nanoseconds per block!</p> <p>That's 3 milliseconds to read the data from a single block. Imagine trying to scan the entire world to find diamonds, or reading multiple blocks in order to calculate a path from A to B.</p>"},{"location":"Optimizations/block_reading.html#why-is-it-slow","title":"Why is it slow?","text":"<p>The reason it's slow is that the code above is doing a lot of work. Let's dive into some of the things that are going on:</p> <ul> <li>We allocate a new <code>BlockPos</code> on the heap, waiting for the OS to find    avaialble memory.</li> <li>We check if the provided BlockPos is outside of the world's height limit.<ul> <li>This reads the <code>bottomY</code> (direct variable access, fairly fast)</li> <li>And computes the <code>topY</code> (requires one addition and one subtraction)</li> </ul> </li> <li>We determine which chunk the block is in<ul> <li>This is fairly fast, but still requires more math: a bit shift and a   \"floor\" operation, which is another comparison</li> <li>This bit shift + \"floor\" operation is done for X and Z coordinates</li> </ul> </li> <li>We check if the current thread is the \"server\" thread. If not, we queue up    the chunk load to be processed by the server thread</li> <li>We initialize a Profiler to measure how long chunk loading takes</li> <li>We combine the X and Z coordinates into a single 8-byte long integer with    more bit shifting and masking</li> <li>We check the last 4 loaded chunks to see if one of these is the one being    accessed. If it is, we return the chunk from cache<ul> <li>This turns out to be a huge time saver later. See below</li> </ul> </li> <li>We allocate a new <code>ChunkPos</code> on the heap, waiting one more for available    memory</li> <li>We determine if the chunk is fully generated or still processing. If still    processing, we defer reading until it's complete</li> <li>We calculate which Chunk Section the block is in</li> <li>We check if the Chunk Section is empty. If so, we return the default    BlockState for \"AIR\"</li> <li>We take the last 4 bits of the X, Y, and Z positions (the remainder when    dividing the positions by 16) to find the relative location within the    Chunk Section</li> <li>We defer to the \"Paletted Container\" to read the data in this X, Y, and Z    position</li> </ul> <p>At this point we still don't have the block data, but our code diverges a bit. Because a Paletted Container consists of two pieces of information:</p> <ol> <li>The \"palette\", containing a de-duplicated list of all blocks in the chunk     section.</li> <li>The \"storage\", containing a list of 4,096 indexes into this palette -- one     for each X, Y, and Z position.</li> </ol> <p>The reason the code diverges is because based on how many unique blocks are in a chunk section, we will use one of four different palette types, and one of two different storage types.</p> <p>Storage Types:</p> <ul> <li>Empty Storage: returns \"0\" for all positions. Very fast.</li> <li>Packed Integer Array: this is a bit more complex</li> </ul> <p>So here's how Packed Integer Array works:</p> <p>Suppose in your 4,096 block chunk section you have 25 distinct blocks. So most blocks are just air, grass, dirt, stone, etc. but there are a handful of less common blocks like oak logs, leaves, coal ore, flowers, etc.</p> <p>All numbers from 0 to 24 can be expressed using 5 bits, so we convert every block into a 5-bit index.</p> <p>Next we tightly stuff all of these 5-bit indexes together, cramming 12 blocks worth of data into a 64-bit (8-byte) long integer. That occupies 60 bits, with 4 bits of wasted space.</p> <p>We create an array of these 64-bit \"packed\" integers, large enough to hold all 4,096 blocks in our chunk section. In this case, 4096 / 12 = 341.33 so we need 342 long integers.</p> <p>Reading a single X, Y, Z value from the Packed Integer Array involves:</p> <ol> <li>Check if the value is within the bounds of the array</li> <li>Figure out which long integer holds the desired bits</li> <li>Read that integer from RAM</li> <li>Mask out the desired bits</li> <li>Shift those bits into the desired position</li> </ol> <p>Palette Types:</p> <ul> <li>Singular Palette: contains a single block state. For example, all blocks in    the chunk section are AIR<ul> <li>Just returns the single block state</li> </ul> </li> <li>Array Palette: contains an array of block states<ul> <li>Once you have the index for a particular block, you simply access that   index in the array</li> </ul> </li> <li>BiMap Palette: contains a bi-directional hash map between integer and block    states<ul> <li>Truthfully I don't know why or when this is preferred by the MineCraft   engine, but I do know that internally it also uses an array</li> </ul> </li> <li>IdList Palette: contains an array of block IDs<ul> <li>Again, I don't really know why or when this is preferred</li> </ul> </li> </ul> <p>For the most part reading from these palettes always comes down to a simple array lookup. However the <code>.get()</code> method often also checks that the index requested is within the bounds of the palette.</p> <p>Now here's where things get particularly bad:</p> <p>In Java, when a class method is overwritten by a child class, this is known as polymorphism. A call to <code>palette.get(x, y, z)</code> might dispatch execution to <code>SingularPalette.get()</code>, <code>ArrayPalette.get()</code>, <code>BiMapPalette.get()</code>, or <code>IdListPalette.get()</code>. We don't know which are compile time, so it has to determine which method to call at runtime.</p> <p>The Just-In-Time (JIT) compiler is really good at optimizing and inlining bytecode for method calls on-the-fly. This means that the first time you call a function you incur fuction-call overhead (pushing parameters on the stack, setting a return pointer, moving the instruction pointer, then unwinding the stack after the function returns) but on subsequent calls all of the code of the method just works without this overhead.</p> <p>The problem is that function inlining only works for monomorphic (one possible set of instructions) or bimorphic (two possible sets of instructions) methods. The moment there are three or more possible code paths (known as \"megamorphic\") that might need to be inlined, the JIT gives up and always dispatches a function call.</p> <p>So while most of what we've done up until now can be optimized to run as fast as possible, palette lookups are always eating this overhead cost.</p>"},{"location":"Optimizations/block_reading.html#whew-thats-a-lot","title":"Whew, that's a lot","text":"<p>So now we know why <code>world.getBlockState()</code> is slow, but what can we do to speed it up? Well there's a few tricks we have up our sleeves.</p>"},{"location":"Optimizations/block_reading.html#1-we-only-read-chunks-after-generation","title":"1. We only read chunks after generation","text":"<p>During block searches (e.g. \"find diamond ores\") and pathfinding (e.g. \"go to position 1500, 70, -800\") Orebit does not read BlockState data from the world. Instead, we rely on two separate representations of the world that are optimized for these two tasks: Regions and NavBlock Grids.</p> <p>The only time we read BlockState data is when we're building or updating these two data structures, which we only do immediately after a chunk has been generated or modified. This means that the chunks we're accessing are always in the \"last 4 chunks touched\" cache, so we avoid the cost of chunk loading.</p> <p>To benchmark this performance I updated my code. Instead of reading 100 blocks randomly within 5 chunks of the player, I read 100 blocks randomly in the last chunk that was generated. On the same hardware this immediately reduced the time to read a block to 1700 nanoseconds. That's a 1,846x speedup!</p> <p>The lesson is that if you're reading multiple blocks from the same chunk, you can amortize the cost of chunk loading over all of the blocks read -- making it essentially zero.</p>"},{"location":"Optimizations/block_reading.html#2-we-can-bypass-world-level-checks","title":"2. We can bypass World-level checks","text":"<p>Because we're hooking into chunk generation and updates, we have an instance of the Chunk already available to us. This means we can skip straight to the last few steps of reading our data, bypassing things like world height checks, thread safety checks, and ChunkPos calculation. This is done using code like so:</p> <pre><code>World world; // The world the chunk resides in\nChunk chunk; // The chunk that just loaded\nint x, y, z; // The block you're interested in\n\nint minY = world.getBottomY();\nint sectionIndex = (y - minY) / 16;\nBlockPos blockPos = new BlockPos(x, y, z);\nBlockState state = chunkSections[sectionIndex].getBlockState(x &amp; 0x0F, y &amp; 0x0F, z &amp; 0x0F);\nstate.isSolidBlock(world, blockPos);\n</code></pre> <p>I updated my code once again and moved it into the <code>CHUNK_LOAD</code> callback. With the latest changes the time to read a single block's data was down to 700 nanoseconds. That's another 2.4x speedup!</p> <p>But we can keep going:</p>"},{"location":"Optimizations/block_reading.html#3-eliminate-memory-allocation","title":"3. Eliminate memory allocation","text":"<p>Some amount of time is spent allocating memory for the BlockPos object that we're creating. However reading the actual BlockState doesn't require this BlockPos any longer now that we're using the ChunkSection API. So why do we still need it?</p> <p>It turns out some blocks have behavior that changes at runtime. A good example of this is the piston arm. The piston arm may be solid, or may not be solid, depending on whether or not it's moving. In order to know if a particular piston arm is moving, we query the world for the specific piston arm at a specific location. Our world queries rely on these BlockPos values.</p> <p>The naive approach here may be to check for these blocks and avoid allocation of a BlockPos all together, with something like this:</p> <pre><code>BlockState state = ...;\nBlock block = state.getBlock();\n\nif (block is PistonExtensionBlock) {\n    // Assume solid\n    return true;\n} else {\n    // Most blocks \"isSolidBlock\" methods don't actually read the \"world\" and\n    // \"pos\" parameters, instead returning static values\n    return state.isSolidBlock(null, null);\n}\n</code></pre> <p>Of course we need to extend this to more than just piston arms. The collection of all blocks that rely on the world and BlockPos to read solidity is:</p> <ul> <li><code>BlockWithEntity</code> -- includes piston arms, sculk sensors, and various others</li> <li><code>BambooBlock</code> -- the exact location within a block for bamboo is randomized</li> <li><code>PointedDripstone</code> -- same as bamboo</li> </ul> <p>I updated my code to check for these three block types and assume they were fully solid, eliminating the allocation of a BlockPos in memory. Now the time to read a single block is up to 900 nanoseconds! It's 28.5% slower, what gives?</p> <p>Well it turns out branch prediction is hard. Every time our code hits this block it has to figure out whether we need to follow the left path or the right path, and we do this per block. So this isn't actually any faster.</p> <p>Can we do something else, though? Yes, we can! MineCraft provides a <code>BlockPos.Mutable</code> class! Using this we can allocate memory once and re-use it in our loop:</p> <pre><code>World world;\nBlockState state = ...;\n\nBlockPos.Mutable pos = new BlockPos.Mutable(0, 0, 0);\n\n// This time I'm actually showing the loop\nfor (int i = 0; i &lt; 100; i++) {\n    int x = (random x in the chunk);\n    int y = (random y in the chunk section);\n    int z = (random z in the chunk);\n    pos.set(x, y, z);\n    sink = state.isSolidBlock(world, pos);\n}\n</code></pre> <p>With this new code avoiding memory allocation and branching, we're down to 600 nanoseconds! A 1.17x speedup!</p> <p>But... can we do even better?</p>"},{"location":"Optimizations/block_reading.html#4-avoiding-megamorphism","title":"4. Avoiding megamorphism","text":"<p>Here is where things start to get really tricky. Remember when I said that reading a palette was slow due to megamorphism? Well we can fix this!</p> <p>We can access the \"paletted container\" of a Chunk Section like so:</p> <pre><code>PalettedContainer&lt;BlockState&gt; container = chunkSection.getBlockStateContainer();\n</code></pre> <p>This is an object that contains both the storage and palette for the raw block data. However, this data is private! So we don't normally have access to it.</p> <p>Through the power of reflection, we can fix this:</p> <pre><code>static {\n    try {\n        dataField = PalettedContainer.class.getDeclaredField(\"data\");\n        dataField.setAccessible(true);\n\n        Class&lt;?&gt; dataClass = Class.forName(\"net.minecraft.world.chunk.PalettedContainer$Data\");\n        storageField = dataClass.getDeclaredField(\"storage\");\n        storageField.setAccessible(true);\n        paletteField = dataClass.getDeclaredField(\"palette\");\n        paletteField.setAccessible(true);\n\n        Class&lt;?&gt; arrayPaletteClass = Class.forName(\"net.minecraft.world.chunk.ArrayPalette\");\n        arrayField = arrayPaletteClass.getDeclaredField(\"array\");\n        arrayField.setAccessible(true);\n\n        Class&lt;?&gt; biMapPaletteClass = Class.forName(\"net.minecraft.world.chunk.BiMapPalette\");\n        biMapField = biMapPaletteClass.getDeclaredField(\"map\");\n        biMapField.setAccessible(true);\n\n        Class&lt;?&gt; idListPaletteClass = Class.forName(\"net.minecraft.world.chunk.IdListPalette\");\n        idListField = idListPaletteClass.getDeclaredField(\"idList\");\n        idListField.setAccessible(true);\n    } catch (NoSuchFieldException | ClassNotFoundException e) {\n        throw new RuntimeException(\"Failed to initialize reflection fields\", e);\n    }\n}\n\npublic void processChunkSection(ChunkSection chunkSection, World world) {\n    PalettedContainer&lt;BlockState&gt; container = chunkSection.getBlockStateContainer();\n    Object data = dataField.get(container);\n    PaletteStorage storage = (PaletteStorage) storageField.get(data);\n    Palette&lt;BlockState&gt; palette = (Palette&lt;BlockState&gt;) paletteField.get(data);\n}\n</code></pre> <p>Now that we've hacked our way through Java's internals, we can add different code based on what type of ChunkSection we're processing:</p> <pre><code>switch (palette) {\n    case SingularPalette&lt;BlockState&gt; singularPalette -&gt; {\n        // All blocks are the same!\n        BlockState everyBlock = singularPalette.get(0);\n        for (int i = 0; i &lt; 100; i++) {\n            int x = ..., y = ..., z = ...;\n            pos.set(x, y, z);\n            sink = everyBlock.isSolidBlock(world, pos);\n        }\n    }\n    case ArrayPalette&lt;BlockState&gt; arrayPalette -&gt; {\n        Object[] array = (Object[]) arrayField.get(arrayPalette);\n        for (int i = 0; i &lt; 100; i++) {\n            int x = ..., y = ..., z = ...;\n            pos.set(x, y, z);\n            BlockState state = (BlockState) array[storage.get(x, y, z)];\n            sink = state.isSolidBlock(world, pos);\n        }\n    }\n    case BiMapPalette&lt;BlockState&gt; blockStateBiMapPalette -&gt; {\n        Int2ObjectBiMap&lt;BlockState&gt; map = (Int2ObjectBiMap&lt;BlockState&gt;) biMapField.get(blockStateBiMapPalette);\n        for (int i = 0; i &lt; 100; i++) {\n            int x = ..., y = ..., z = ...;\n            pos.set(x, y, z);\n            BlockState state = (BlockState) map.get(storage.get(x, y, z));\n            sink = state.isSolidBlock(world, pos);\n        }\n    }\n    case IdListPalette&lt;BlockState&gt; idListPalette -&gt; {\n        IndexedIterable&lt;BlockState&gt; idList = (IndexedIterable&lt;BlockState&gt;) idListField.get(idListPalette);\n        for (int i = 0; i &lt; 100; i++) {\n            int x = ..., y = ..., z = ...;\n            pos.set(x, y, z);\n            BlockState state = (BlockState) idList.get(storage.get(x, y, z));\n            sink = state.isSolidBlock(world, pos);\n        }\n    }\n    case null, default -&gt; {\n        throw new RuntimeException(\"Unexpected palette type: \" + palette);\n    }\n}\n</code></pre> <p>This seems like a lot of code and a lot of overkill, but it gives us two big wins:</p> <p>First, we have inlined the calls to <code>palette.get()</code>, so we now avoid function call overhead.</p> <p>Second, roughly 60% of all ChunkSections in MineCraft contain nothing but air (ChunkSections above Y = 80). This means that 60% of the time we will hit our SingularPalette, avoiding far more work.</p> <p>Benchmarking all cases:</p> <ul> <li>When using a SingularPalette, the average time to read a block is down to    2.5 nanoseconds. A 240x speedup!</li> <li>When using an ArrayPalette, the average time to read a block is down to 14    nanoseconds. A 43x speedup!</li> <li>When using a BiMapPalette, the average time to read a block is down to 27    nanoseconds. A 22x speedup!</li> <li>In my testing I didn't see an IdListPalette, so I don't know when these are    used.</li> </ul> <p>Given that 60% of ChunkSections are using SingularPalette, the average time to read a block is now:</p> <p>\\(60% x 2.5 + 20% x 14 + 20% x 27 = 1.5 + 2.8 + 5.4 = 9.7\\) nanoseconds.</p> <p>This is a 62x speedup over the previous best case! But... the question remains... can we do better?</p>"},{"location":"Optimizations/block_reading.html#5-limit-reflective-access","title":"5. Limit reflective access","text":"<p>We pay a cost every time we access a field via reflection. Reflection requires Java to introspect about its own bytecode at runtime, eliminating many potential gains from the JIT compiler. While we were able to avoid megamorphism, we now incur the full wrath of unoptimized Java code for every single block we read.</p> <p>So what can we do? Are we at the end of our optimization journey?</p> <p>Not by a long shot!</p> <p>So far we've benchmarked random access to blocks in a ChunkSection. But when we're generating our NavBlock Grid and our Regions, we're going to scan the entire ChunkSection in order. This means that after reading one block, we know the next block we're going to read is always the next one in sequence.</p> <p>It just so happens that the <code>PaletteStorage</code> abstract class provides us with an iterator that will loop over all values in the ChunkSection in order. This means we only have to access the reflected field once, to call <code>.forEach</code>. After this, the iterator handles everything with beautifully optimized code:</p> <pre><code>// This example is just for ArrayPalette, but the same applies to all others\ncase ArrayPalette&lt;BlockState&gt; arrayPalette -&gt; {\n    Object[] array = (Object[]) arrayField.get(palette);\n    storage.forEach(index -&gt; {\n        int x = ..., y = ..., z = ...;\n        pos.set(x, y, z);\n        BlockState state = (BlockState) array[index];\n        sink = state.isSolidBlock(world, pos);\n    });\n}\n</code></pre> <p>We're now no longer benchmarking the average time to read 100 random blocks, but the average time to read all blocks in a ChunkSection. Dividing this by 4,096 gives us the average time per block. So what do our times look like now?</p> <ul> <li>SingularPalette: 3.5 nanoseconds</li> <li>In this case the cost of the iterator actually increases the time to read</li> <li>ArrayPalette: 10 nanoseconds</li> <li>BiMapPalette: 13 nanoseconds</li> <li>IdListPalette: no data</li> </ul> <p>Our average read time per block is now:</p> <p>\\(60% x 3.5 + 20% x 10 + 20% x 13 = 2.1 + 2.0 + 2.6 = 6.7\\) nanoseconds.</p> <p>That's a 1.44x speedup over the previous. But... can we do better?</p>"},{"location":"Optimizations/block_reading.html#6-maybe","title":"6. Maybe...","text":"<p>PackedIntgerArray already has a very optimal <code>forEach</code> method that only loads each long integer once, then repeatedly shifts off values of the appropriate size in order to call our method once per value.</p> <p>Also recall that the JIT already optimizes and inlines functions if they are either monomorphic or bimorphic. In the case of PaletteStorage, we only have two subclasses, not four, meaning our method call is bimorphic and the JIT is able to handle this for us.</p> <p>But I do have a few ideas...</p>"},{"location":"Optimizations/object_pooling.html","title":"Object pooling","text":""},{"location":"Optimizations/object_pooling.html#primer-on-ram","title":"Primer on RAM","text":"<p>Every program on your computer must share the same RAM. In order to ensure programs play nicely, the Operating System assigns sections of RAM to each process. For example, when I launch a program the Operating System may set aside 50 megabytes of the 16,000 megabytes available to my computer and say \"this memory is exclusively for use by program A\".</p> <p>Throughout its execution, the program may decide it needs more memory in order to complete its tasks. When this happens, the program asks the Operating System for additional RAM and the Operating System finds an unused section of memory, assigning it to the program. This process is known as \"memory allocation\".</p> <p>Memory allocation can take some time. Using memory that is already assigned to your program is much, much faster.</p> <p>When your program is finished with memory, it has the option to give it back to the Operating System so that another program can use it later. This process is called \"memory deallocation\". This is significantly faster than memory allocation. A completely different issue arises here, though.</p> <p>Theoretically every piece of memory should be allocated once and deallocated once. However subtle bugs in code can lead to allocating memory and never deallocating it (memory leak) or attempting to deallocate it twice (double free). You might also try to read from memory afer it has been deallocated (segmentation fault).</p> <p>To save developers from these mistakes, many modern programming languages (Java included) have what's known as a \"Garbage Collector\". The Garabge Collector's job is to scan your memory occasionally looking for memory that is no longer being used and is safe to deallocate.</p> <p>The problem with Garbage Collectors is that they're slow. Very slow. So the more we can avoid them, the faster we'll be.</p>"},{"location":"Optimizations/object_pooling.html#object-pooling","title":"Object Pooling","text":"<p>TBD</p>"},{"location":"getting_started/installation.html","title":"Installation","text":""},{"location":"getting_started/installation.html#prerequisites","title":"Prerequisites","text":"<p>Orebit is a mod for MineCraft 1.21.4. It is not compatible with any older or newer versions of the game. I may update it to 1.21.5 in the future, but for now this is what you get.</p> <p>Orebit is a Fabric mod, so you will need to install Fabric and Fabric API. You can find instructions for that here.</p>"},{"location":"getting_started/installation.html#installing-orebit","title":"Installing Orebit","text":"<p>Download the latest version of Orebit from the releases page. Then extract the contents of the zip file into your <code>mods</code> folder. To find your <code>mods</code> folder:</p> <ul> <li>On Windows, it is located at <code>%AppData%/.minecraft/mods</code></li> <li>On Mac, it is located at <code>~/Library/Application Support/minecraft/mods</code></li> <li>On Linux, it is located at <code>~/.minecraft/mods</code></li> </ul>"}]}